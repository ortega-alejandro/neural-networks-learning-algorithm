# Stochastic Gradient Descent for Neural Networks

Final project for Math 465/CS 445 _High Dimensional Data Analysis_ taught by Dr. Paul Bendich @ Duke University, Fall 2017. This project consisted of a 20+ minute lecture describing the backpropagation via gradient descent algorithm that neural networks use to learn, and the improvements that stochastic gradient descent provide over standard (or batch) gradient descent in high dimensions. Included is Programming Assignment 4 from the Stanford Machine Learning Course, which covers learning with neural networks.

## References
* Ng, Andrew. "Neural Networks: Learning." _Coursera_ Coursera.org 11 November 2017 Accessed.
* "Stochastic Gradient Descent." _Understanding Machine Learning: from Theory to Algorithms_, by Shai Shalev-Shwartz and Shai Ben-David, Cambridge University Press, 2016, pp. 184â€“201.

### Project Members: Alejandro Ortega, Peter Mikhael

### Course Grade Earned: A
